
[[filebeat-configuration-details]]
== Configuration Options

The configuration file of Filebeat uses http://yaml.org/[YAML] as any other Beat.
To start with the configuration it is best to have a look at the default configuration. It is described in detail
what each configuration option is for and how it can be used. Remove the items that are not needed for your setup.

The _etc/filebeat.yml_ consists of the following sections:

* {libbeat}/configuration.html#configuration-shipper[Shipper]
* {libbeat}/configuration.html#configuration-output[Output]
* <<configuration-filebeat-options>>
* {libbeat}/configuration.html#configuration-logging[Logging (optional)]
* {libbeat}/configuration.html#configuration-run-options[Run options (optional)]

[[configuration-filebeat-options]]
=== Filebeat

==== Prospectors

Contains a list of prospector items. Each prospector item is described below.

[source,yaml]
-------------------------------------------------------------------------------------
filebeat:
  prospectors: 1024
-------------------------------------------------------------------------------------

Every prospector item starts with a -. Inside are the prospector specific configs defined
and a list of paths is added that should be crawled. The config fields itself are described
in the config below.

[source,yaml]
-------------------------------------------------------------------------------------
############################# Filbeat ######################################
filebeat:
  # List of prospectors to fetch data.
  prospectors:
    # Each - is a prospector. Below are the prospector specific configurations
    -
      # Paths that should be crawled and fetched. Glob based paths.
      # For each file found under this path, a harvester is started.
      paths:
        - "/var/log/*.log"
      # - c:\programdata\elasticsearch\logs\*

      # Type of the files. Based on this the way the file is read is decided.
      # The different types cannot be mixed in one prospector
      #
      # Possible options are:
      # * log: Reads every line of the log file (default)
      # * stdin: Reads the standard in
      input_type: log

      # Optional additional fields. These field can be freely picked
      # to add additional information to the crawled log files for filtering
      #fields:
      #  level: debug
      #  review: 1

      # Set to true to store the additional fields as top level fields instead
      # of under the "fields" sub-dictionary. In case of name conflicts with the
      # fields added by Filebeat itself, the custom fields overwrite the default
      # fields.
      #fields_under_root: false

      # Ignore files which were modified more then the defined timespan in the past
      # Time strings like 2h (2 hours), 5m (5 minutes) can be used.
      #ignore_older:

      # Scan frequency in seconds.
      # How often these files should be checked for changes. In case it is set
      # to 0s, it is done as often as possible. Default: 10s
      #scan_frequency: 10s

      # Defines the buffer size every harvester uses when fetching the file
      #harvester_buffer_size: 16384

      # Setting tail_files to true means filebeat starts readding new files at the end
      # instead of the beginning. If this is used in combination with log rotation
      # this can mean that the first entries of a new file are skipped.
      #tail_files: false

      # Configure the file encoding for reading files with international characters
      # following the W3C recommendation for HTML5 (http://www.w3.org/TR/encoding).
      # Some sample encodings:
      #   plain, utf-8, utf-16be-bom, utf-16be, utf-16le, big5, gb18030, gbk,
      #    hz-gb-2312, euc-kr, euc-jp, iso-2022-jp, shift-jis, ...
      #encoding: plain
-------------------------------------------------------------------------------------

===== paths

A list of glob based paths that should be crawled and fetched. For each file found under this path, a harvester is
started. Each path is defined one per line.

===== input_type

It has two options:

    * log:  Reads every line of the log file (default)
    * stdin: Reads the standard in

The type value will be put into each event published to Logstash and
Elasticsearch in the 'input_type' field.

[[configuration-fields]]
===== fields

Add optionally couple of fields to be included to the exported fields by the currently configured
Filebeat instance. These fields can be freely picked to add additional information to the crawled
log files for filtering.

[source,yaml]
-------------------------------------------------------------------------------------
fields:
    level: debug
    review: 1

-------------------------------------------------------------------------------------

===== fields_under_root

If set to true, the custom <<configuration-fields>> are stored as top level into the output
document instead of being grouped under a `fields` sub-dictionary. In case of conflicts with
the fields names added by Filebeat, the custom fields overwrite the existing fields.

===== ignore_older

If set, ignores the files which were modified more then the defined timespan in the past
Time strings like 2h (2 hours), 5m (5 minutes) can be used. Default is set to 10m.

===== scan_frequency

Scan frequency specifies how often the prospector checks for new files in the
paths that are specified for harvesting. For example, if you specify a glob like
`/var/log/*`, the directory is scanned for files using the frequency specified by
scan_frequency. If you specify 0s, the directory is scanned as frequently as
possible. We recommend that you do not specify 0. The default setting is 10s.

===== document_type

Defines the event its type value to be used for published lines read by
harvesters. The document_type will be used by Elasticsearch output as document
type. Default value is `log`.


===== harvester_buffer_size

Defines the buffer size every harvester uses when fetching the file. By default is 16384.


===== tail_files

If this option is set to true, Filebeat starts reading new files at the end of each file instead of the beginning. When this option is used in combination with log rotation, it's possible that the first log entries in a new file might be skipped. The default setting is false.

NOTE: You can use this setting to avoid indexing old log lines when you run Filebeat on a set of log files for the first time. After the first run, we recommend disabling this option, or you risk losing lines during file rotation.

===== backoff

Backoff values define how aggressively Filebeat crawls new files for updates
The default values can be used in most cases. Backoff defines how long it is waited
to check a file again after EOF is reached. Default is 1s which means the file
is checked every second if new lines were added. This leads to a near real time crawling.
Every time a new line appears, backoff is reset to the initial value.
Default: 1s

===== max_backoff

Max backoff defines what the maximum waiting time is. After having backed off multiple times
from checking the files, the waiting time will never exceed max_backoff independent of the
backoff factor. Having it set to 10s means in the worst case a new line can be added to a log
file after having backed off multiple times, it takes a maximum of 10s to read the new line.
Default: 10s

===== backoff_factor

The backoff factor defines how fast the waiting time is increased. The bigger the backoff factor,
the faster the max_backoff value is reached. The backoff increments exponential.
The minimal value allowed is 1. If this value is set to 1 it means backoff algorithm is disabled
and the backoff value is used for waiting for new lines.
The backoff value will be multiplied each time with the backoff_factor until max_backoff is reached.
Default: 2

===== partial_line_waiting

Defines the time on how long the harvester will wait for a line to be completed.
Sometimes a lines it not completely written when checked by Filebeat. Filebeat
will wait for the time defined below so the system can complete the line.
In case the line is not completed in this time, the line will be skipped.
Default: 5s

===== force_close_windows_files

This option closes a file on windows, as soon as the file name changes.
This config option is windows only. Filebeat keeps the files it's reading open. This can cause
issues when the file is removed, as the file will not be fully removed until also Filebeat closes
the reading. Filebeat closes the file handler after ignore_older. During this time no new file with the
same name can be created. Turning this feature on the other hand can lead to loss of data
on rotate files. It can happen that after file rotation the beginning of the new
file is skipped, as the reading starts at the end. We recommend to leave this option on false
but lower the ignore_older value to release files faster.
Default: false

===== spool_size

Event count spool threshold - forces network flush if exceeded.

-------------------------------------------------------------------------------------
filebeat:
  spool_size: 1024
-------------------------------------------------------------------------------------


===== idle_timeout

Defines how often the spooler is flushed. After idle_timeout the spooler is
Flush even though spool_size is not reached. The value must be given as duration string.

[source,yaml]
-------------------------------------------------------------------------------------
filebeat:
  idle_timeout: 5s
-------------------------------------------------------------------------------------



===== registry_file

Name of the registry file. Per default it is put in the current working
directory. In case the working directory is changed after when running
Filebeat again, indexing starts from the beginning again.

[source,yaml]
-------------------------------------------------------------------------------------
filebeat:
  registry_file: .filebeat
-------------------------------------------------------------------------------------


===== config_dir

Full Path to directory with additional prospector configuration files. Each file must end with .yml
These config files must have the full Filebeat config hierarchy inside, but only
the prospector part is processed. All global options like spool_size are ignored.
The config_dir MUST point to a different directory then where the main Filebeat config file is in.

[source,yaml]
-------------------------------------------------------------------------------------
filebeat:
  config_dir: path/to/configs
-------------------------------------------------------------------------------------

===== encoding

Configures the file encoding for reading file with international characters.
Encodings names as [recommended by the W3C for use in HTML5](http://www.w3.org/TR/encoding/).

Some sample encodings from W3C recommendation:

    * plain, latin1, utf-8, utf-16be-bom, utf-16be, utf-16le, big5, gb18030, gbk, hz-gb-2312,
    * euc-kr, euc-jp, iso-2022-jp, shift-jis, ...

The `plain` encoding is special, as it does not validates or transforms any input.
